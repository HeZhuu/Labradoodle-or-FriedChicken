load("/Users/chenyun/Desktop/GR5243/spr2017-proj3-grp1/lib/Random_Forests/output/RFs_fit2_train.RData")
load("/Users/chenyun/Desktop/GR5243/spr2017-proj3-grp1/lib/Random_Forests/output/workspace_fit2.RData")
fit.1
fit.1$ntree
fit.1$mtry
load("/Users/chenyun/Desktop/GR5243/spr2017-proj3-grp1/lib/Random_Forests/output/RFs_fit1_train.RData")
fit.1$mtry
fit.1$ntree
load("/Users/chenyun/Desktop/GR5243/spr2017-proj3-grp1/lib/Random_Forests/output/workspace_fit2.RData")
load("/Users/chenyun/Desktop/GR5243/spr2017-proj3-grp1/lib/Random_Forests/output/workspace_fit2.RData")
load("/Users/chenyun/Desktop/GR5243/spr2017-proj3-grp1/lib/Random_Forests/output/RFs_fit2_train.RData")
knitr::opts_chunk$set(echo = TRUE)
opts_knit$set(root.dir = "~/Desktop/GR5243/spr2017-proj3-grp1")
library(knitr)
opts_knit$set(root.dir = "~/Desktop/GR5243/spr2017-proj3-grp1")
ggplot(data = data.frame(cv.error)) + geom_point(aes(x = 1:K, y = cv.error), color = "blue")
library(knitr)
library(randomForest)
library(ggplot2)
ggplot(data = data.frame(cv.error)) + geom_point(aes(x = 1:K, y = cv.error), color = "blue")
best <- which.min(cv.error)
system.time(fit.1 <- tuneRF(x.train[s != best,], as.factor(y.train[s != best]), ntree = 70, doBest = TRUE))
fit.1$ntree
summary(fit.1)
fit.1 <- tuneRF(x.train[s != best,], as.factor(y.train[s != best]), ntree = 70, doBest = TRUE)
fit.1$ntree
?tureRF
?tuneRF
system.time(fit.1 <- tuneRF(x.train[s != best,], as.factor(y.train[s != best]), ntreeTry = 70, doBest = TRUE))
fit.1$ntree
system.time(fit.1 <- tuneRF(x.train[s != best,], as.factor(y.train[s != best]), ntreeTry = 70, doBest = FALSE))
fit.1
randomForest(fit.1)
randomForest(fit.1, ntree = 70)
?randomForest
randomForest(x.train[s != best,], as.factor(y.train[s != best]), ntree = 70)
randomForest(x.train[s != best,], as.factor(y.train[s != best]), ntree = 500)
test <- tuneRF(x.train[s != best,], as.factor(y.train[s != best]), ntree = 70)
test
predict(test, x.train)
test <- randomForest(x.train[s != best,], as.factor(y.train[s != best]), ntree = 70)
pre <- predict(test, x.train)
table(pre, x.train)
head(pre)
table(pre, y.train)
mean(pre != y.train)
pre <- predict(test, x.test)
mean(pre != y.test)
test
knitr::opts_chunk$set(echo = TRUE)
#opts_knit$set(root.dir = "~/Desktop/GR5243/spr2017-proj3-grp1")
if(!require("randomForest")){
install.packages("randomForest")
}
if(!require("ggplot2")){
install.packages("ggplot2")
}
if(!require("knitr")){
install.packages("knitr")
}
library(knitr)
library(randomForest)
library(ggplot2)
run.cv=TRUE # run cross-validation on the training set
K <- 5 # number of CV folds
run.feature.train = TRUE # process features for training set
run.test = TRUE # run evaluation on an independent test set
run.feature.test = TRUE # process features for test set
proportion = 0.75 # training set proportion
seed = 618 # set seed
label.train <- c(rep(0,1000), rep(1,1000))
features.1 <- read.csv("chickf.csv")
getwd()
setwd("~/Desktop/GR5243/spr2017-proj3-grp1/lib/Features/GIST")
features.1 <- read.csv("chickf.csv")
setwd("~/Desktop/GR5243/spr2017-proj3-grp1/lib/Features/GIST")
features.1 <- read.csv("chickf.csv")
opts_knit$set(root.dir = "~/Desktop/GR5243/spr2017-proj3-grp1/lib/Features/GIST")
features.1 <- read.csv("chickf.csv")
View(features.1)
features.1 <- read.csv("chickf.csv", header = F)
features.2 <- read.csv("dogf.csv", header = F)
features <- rbind(features.1, features.2)
n <- dim(features)[1]
set.seed(seed)
index <- sample(n, n*proportion)
x.train <- features[index,]
y.train <- as.vector(label.train[index,])
label.train <- as.vector(c(rep(0,1000), rep(1,1000)))
y.train <- label.train[index]
x.test <- features[-index,]
y.test <- label.train[-index,]
y.test <- label.train[-index]
m <- length(y.train)
m.fold <- floor(m/K)
set.seed(seed)
s <- sample(rep(1:K, c(rep(m.fold, K-1), m-(K-1)*m.fold)))
cv.error <- rep(NA, K)
# tree <- sqrt(dim(X)[2])
for (i in 1:K){
train.data <- x.train[s != i,]
train.label <- y.train[s != i]
test.data <- x.train[s == i,]
test.label <- y.train[s == i]
# fit <- tuneRF(train.data, as.factor(train.label), doBest = TRUE) #test ntree = 500
fit <- tuneRF(train.data, as.factor(train.label), ntree = 70, doBest = TRUE) #test ntree = 70
pred <- predict(fit, test.data)
cv.error[i] <- mean(pred != test.label)
}
m <- length(y.train)
m.fold <- floor(m/K)
set.seed(seed)
s <- sample(rep(1:K, c(rep(m.fold, K-1), m-(K-1)*m.fold)))
cv.error <- rep(NA, K)
# tree <- sqrt(dim(X)[2])
for (i in 1:K){
train.data <- x.train[s != i,]
train.label <- y.train[s != i]
test.data <- x.train[s == i,]
test.label <- y.train[s == i]
fit <- tuneRF(train.data, as.factor(train.label), doBest = TRUE) #test ntree = 500
pred <- predict(fit, test.data)
cv.error[i] <- mean(pred != test.label)
}
ggplot(data = data.frame(cv.error)) + geom_point(aes(x = 1:K, y = cv.error), color = "blue")
best <- which.min(cv.error)
system.time(fit.1 <- tuneRF(x.train[s != best,], as.factor(y.train[s != best]), ntree = 70, doBest = TRUE))
save(fit.1, file="./lib/Random_Forests/output/RFs_fit_GIST.RData")
save(fit.1, file="./RFs_fit_GIST.RData")
getwd()
train_pred <- predict(fit.1, x.train)
train_error <- mean(train_pred != y.train)
train_error
test_pred <- predict(fit.1, x.test)
test_error <- mean(test_pred != y.test)
test_error
fit.1$mtry
